{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (650, 5)\n",
      "   layer_height  extrusion  speed  layer_width  over-under\n",
      "0             8          2     80         49.0           1\n",
      "1             8          2     80         48.3           1\n",
      "2             8          2     80         48.4           1\n",
      "3             8          2     80         48.8           1\n",
      "4             8          2     80         48.4           1\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Data Loading\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow / Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "import itertools\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load data (using winter data as in your original code)\n",
    "data_path = 'data/data_3dcp_wClean.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Basic information\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (520, 3)\n",
      "Test set shape: (130, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Preprocessing - Train/Test Split\n",
    "# Define features and target\n",
    "X = data[['extrusion', 'layer_height', 'layer_width']]\n",
    "y = data['speed']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define the Neural Network Model Function\n",
    "def create_nn_model(input_dim, model_depth=2, layer_size=32, l1_rate=1e-3, l2_rate=1e-3,\n",
    "                    dropout_rate=0.0, learning_rate=1e-2):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    \n",
    "    for _ in range(model_depth):\n",
    "        model.add(Dense(layer_size, activation='elu',\n",
    "                        kernel_regularizer=l1_l2(l1_rate, l2_rate)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter search progress:   0%|          | 0/576 [00:00<?, ?iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Combination ('robust', 2, 32, 0.0, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 2: Combination ('robust', 2, 32, 0.0, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 3: Combination ('robust', 2, 32, 0.0, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 4: Combination ('robust', 2, 32, 0.0, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 5: Combination ('robust', 2, 32, 0.0, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 6: Combination ('robust', 2, 32, 0.0, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 7: Combination ('robust', 2, 32, 0.0, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 8: Combination ('robust', 2, 32, 0.0, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 9: Combination ('robust', 2, 32, 0.0, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 10: Combination ('robust', 2, 32, 0.0, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 11: Combination ('robust', 2, 32, 0.0, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 12: Combination ('robust', 2, 32, 0.0, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 13: Combination ('robust', 2, 32, 0.0, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 14: Combination ('robust', 2, 32, 0.0, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 15: Combination ('robust', 2, 32, 0.0, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 16: Combination ('robust', 2, 32, 0.0, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 17: Combination ('robust', 2, 32, 0.0, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 18: Combination ('robust', 2, 32, 0.0, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 19: Combination ('robust', 2, 32, 0.0, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 20: Combination ('robust', 2, 32, 0.0, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 21: Combination ('robust', 2, 32, 0.0, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 22: Combination ('robust', 2, 32, 0.0, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 23: Combination ('robust', 2, 32, 0.0, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 24: Combination ('robust', 2, 32, 0.0, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 25: Combination ('robust', 2, 32, 0.2, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 26: Combination ('robust', 2, 32, 0.2, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 27: Combination ('robust', 2, 32, 0.2, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 28: Combination ('robust', 2, 32, 0.2, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 29: Combination ('robust', 2, 32, 0.2, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 30: Combination ('robust', 2, 32, 0.2, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 31: Combination ('robust', 2, 32, 0.2, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 32: Combination ('robust', 2, 32, 0.2, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 33: Combination ('robust', 2, 32, 0.2, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 34: Combination ('robust', 2, 32, 0.2, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 35: Combination ('robust', 2, 32, 0.2, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 36: Combination ('robust', 2, 32, 0.2, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 37: Combination ('robust', 2, 32, 0.2, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 38: Combination ('robust', 2, 32, 0.2, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 39: Combination ('robust', 2, 32, 0.2, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 40: Combination ('robust', 2, 32, 0.2, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 41: Combination ('robust', 2, 32, 0.2, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 42: Combination ('robust', 2, 32, 0.2, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 43: Combination ('robust', 2, 32, 0.2, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 44: Combination ('robust', 2, 32, 0.2, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 45: Combination ('robust', 2, 32, 0.2, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 46: Combination ('robust', 2, 32, 0.2, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 47: Combination ('robust', 2, 32, 0.2, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 48: Combination ('robust', 2, 32, 0.2, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 49: Combination ('robust', 2, 64, 0.0, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 50: Combination ('robust', 2, 64, 0.0, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 51: Combination ('robust', 2, 64, 0.0, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 52: Combination ('robust', 2, 64, 0.0, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 53: Combination ('robust', 2, 64, 0.0, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 54: Combination ('robust', 2, 64, 0.0, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 55: Combination ('robust', 2, 64, 0.0, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 56: Combination ('robust', 2, 64, 0.0, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 57: Combination ('robust', 2, 64, 0.0, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 58: Combination ('robust', 2, 64, 0.0, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 59: Combination ('robust', 2, 64, 0.0, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 60: Combination ('robust', 2, 64, 0.0, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 61: Combination ('robust', 2, 64, 0.0, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 62: Combination ('robust', 2, 64, 0.0, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 63: Combination ('robust', 2, 64, 0.0, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 64: Combination ('robust', 2, 64, 0.0, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 65: Combination ('robust', 2, 64, 0.0, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 66: Combination ('robust', 2, 64, 0.0, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 67: Combination ('robust', 2, 64, 0.0, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 68: Combination ('robust', 2, 64, 0.0, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 69: Combination ('robust', 2, 64, 0.0, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 70: Combination ('robust', 2, 64, 0.0, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 71: Combination ('robust', 2, 64, 0.0, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 72: Combination ('robust', 2, 64, 0.0, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 73: Combination ('robust', 2, 64, 0.2, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 74: Combination ('robust', 2, 64, 0.2, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 75: Combination ('robust', 2, 64, 0.2, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 76: Combination ('robust', 2, 64, 0.2, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 77: Combination ('robust', 2, 64, 0.2, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 78: Combination ('robust', 2, 64, 0.2, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 79: Combination ('robust', 2, 64, 0.2, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 80: Combination ('robust', 2, 64, 0.2, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 81: Combination ('robust', 2, 64, 0.2, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 82: Combination ('robust', 2, 64, 0.2, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 83: Combination ('robust', 2, 64, 0.2, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 84: Combination ('robust', 2, 64, 0.2, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 85: Combination ('robust', 2, 64, 0.2, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 86: Combination ('robust', 2, 64, 0.2, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 87: Combination ('robust', 2, 64, 0.2, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 88: Combination ('robust', 2, 64, 0.2, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 89: Combination ('robust', 2, 64, 0.2, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 90: Combination ('robust', 2, 64, 0.2, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 91: Combination ('robust', 2, 64, 0.2, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 92: Combination ('robust', 2, 64, 0.2, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 93: Combination ('robust', 2, 64, 0.2, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 94: Combination ('robust', 2, 64, 0.2, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 95: Combination ('robust', 2, 64, 0.2, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 96: Combination ('robust', 2, 64, 0.2, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 97: Combination ('robust', 2, 96, 0.0, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 98: Combination ('robust', 2, 96, 0.0, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 99: Combination ('robust', 2, 96, 0.0, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 100: Combination ('robust', 2, 96, 0.0, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 101: Combination ('robust', 2, 96, 0.0, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 102: Combination ('robust', 2, 96, 0.0, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 103: Combination ('robust', 2, 96, 0.0, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 104: Combination ('robust', 2, 96, 0.0, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 105: Combination ('robust', 2, 96, 0.0, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 106: Combination ('robust', 2, 96, 0.0, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 107: Combination ('robust', 2, 96, 0.0, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 108: Combination ('robust', 2, 96, 0.0, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 109: Combination ('robust', 2, 96, 0.0, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 110: Combination ('robust', 2, 96, 0.0, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 111: Combination ('robust', 2, 96, 0.0, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 112: Combination ('robust', 2, 96, 0.0, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 113: Combination ('robust', 2, 96, 0.0, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 114: Combination ('robust', 2, 96, 0.0, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 115: Combination ('robust', 2, 96, 0.0, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 116: Combination ('robust', 2, 96, 0.0, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 117: Combination ('robust', 2, 96, 0.0, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 118: Combination ('robust', 2, 96, 0.0, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 119: Combination ('robust', 2, 96, 0.0, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 120: Combination ('robust', 2, 96, 0.0, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 121: Combination ('robust', 2, 96, 0.2, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 122: Combination ('robust', 2, 96, 0.2, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 123: Combination ('robust', 2, 96, 0.2, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 124: Combination ('robust', 2, 96, 0.2, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 125: Combination ('robust', 2, 96, 0.2, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 126: Combination ('robust', 2, 96, 0.2, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 127: Combination ('robust', 2, 96, 0.2, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 128: Combination ('robust', 2, 96, 0.2, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 129: Combination ('robust', 2, 96, 0.2, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 130: Combination ('robust', 2, 96, 0.2, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 131: Combination ('robust', 2, 96, 0.2, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 132: Combination ('robust', 2, 96, 0.2, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 133: Combination ('robust', 2, 96, 0.2, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 134: Combination ('robust', 2, 96, 0.2, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 135: Combination ('robust', 2, 96, 0.2, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 136: Combination ('robust', 2, 96, 0.2, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 137: Combination ('robust', 2, 96, 0.2, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 138: Combination ('robust', 2, 96, 0.2, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 139: Combination ('robust', 2, 96, 0.2, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 140: Combination ('robust', 2, 96, 0.2, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 141: Combination ('robust', 2, 96, 0.2, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 142: Combination ('robust', 2, 96, 0.2, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 143: Combination ('robust', 2, 96, 0.2, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 144: Combination ('robust', 2, 96, 0.2, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 145: Combination ('robust', 3, 32, 0.0, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 146: Combination ('robust', 3, 32, 0.0, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 147: Combination ('robust', 3, 32, 0.0, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 148: Combination ('robust', 3, 32, 0.0, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 149: Combination ('robust', 3, 32, 0.0, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 150: Combination ('robust', 3, 32, 0.0, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 151: Combination ('robust', 3, 32, 0.0, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 152: Combination ('robust', 3, 32, 0.0, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 153: Combination ('robust', 3, 32, 0.0, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 154: Combination ('robust', 3, 32, 0.0, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 155: Combination ('robust', 3, 32, 0.0, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 156: Combination ('robust', 3, 32, 0.0, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 157: Combination ('robust', 3, 32, 0.0, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 158: Combination ('robust', 3, 32, 0.0, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 159: Combination ('robust', 3, 32, 0.0, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 160: Combination ('robust', 3, 32, 0.0, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 161: Combination ('robust', 3, 32, 0.0, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 162: Combination ('robust', 3, 32, 0.0, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 163: Combination ('robust', 3, 32, 0.0, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 164: Combination ('robust', 3, 32, 0.0, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 165: Combination ('robust', 3, 32, 0.0, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 166: Combination ('robust', 3, 32, 0.0, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 167: Combination ('robust', 3, 32, 0.0, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 168: Combination ('robust', 3, 32, 0.0, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 169: Combination ('robust', 3, 32, 0.2, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 170: Combination ('robust', 3, 32, 0.2, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 171: Combination ('robust', 3, 32, 0.2, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 172: Combination ('robust', 3, 32, 0.2, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 173: Combination ('robust', 3, 32, 0.2, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 174: Combination ('robust', 3, 32, 0.2, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 175: Combination ('robust', 3, 32, 0.2, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 176: Combination ('robust', 3, 32, 0.2, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 177: Combination ('robust', 3, 32, 0.2, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 178: Combination ('robust', 3, 32, 0.2, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 179: Combination ('robust', 3, 32, 0.2, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 180: Combination ('robust', 3, 32, 0.2, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 181: Combination ('robust', 3, 32, 0.2, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 182: Combination ('robust', 3, 32, 0.2, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 183: Combination ('robust', 3, 32, 0.2, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 184: Combination ('robust', 3, 32, 0.2, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 185: Combination ('robust', 3, 32, 0.2, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 186: Combination ('robust', 3, 32, 0.2, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 187: Combination ('robust', 3, 32, 0.2, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 188: Combination ('robust', 3, 32, 0.2, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 189: Combination ('robust', 3, 32, 0.2, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 190: Combination ('robust', 3, 32, 0.2, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 191: Combination ('robust', 3, 32, 0.2, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 192: Combination ('robust', 3, 32, 0.2, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 193: Combination ('robust', 3, 64, 0.0, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 194: Combination ('robust', 3, 64, 0.0, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 195: Combination ('robust', 3, 64, 0.0, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 196: Combination ('robust', 3, 64, 0.0, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 197: Combination ('robust', 3, 64, 0.0, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 198: Combination ('robust', 3, 64, 0.0, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 199: Combination ('robust', 3, 64, 0.0, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 200: Combination ('robust', 3, 64, 0.0, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 201: Combination ('robust', 3, 64, 0.0, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 202: Combination ('robust', 3, 64, 0.0, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 203: Combination ('robust', 3, 64, 0.0, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 204: Combination ('robust', 3, 64, 0.0, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 205: Combination ('robust', 3, 64, 0.0, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 206: Combination ('robust', 3, 64, 0.0, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 207: Combination ('robust', 3, 64, 0.0, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 208: Combination ('robust', 3, 64, 0.0, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 209: Combination ('robust', 3, 64, 0.0, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 210: Combination ('robust', 3, 64, 0.0, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 211: Combination ('robust', 3, 64, 0.0, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 212: Combination ('robust', 3, 64, 0.0, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 213: Combination ('robust', 3, 64, 0.0, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 214: Combination ('robust', 3, 64, 0.0, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 215: Combination ('robust', 3, 64, 0.0, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 216: Combination ('robust', 3, 64, 0.0, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 217: Combination ('robust', 3, 64, 0.2, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 218: Combination ('robust', 3, 64, 0.2, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 219: Combination ('robust', 3, 64, 0.2, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 220: Combination ('robust', 3, 64, 0.2, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 221: Combination ('robust', 3, 64, 0.2, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 222: Combination ('robust', 3, 64, 0.2, 64, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 223: Combination ('robust', 3, 64, 0.2, 64, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 224: Combination ('robust', 3, 64, 0.2, 64, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 225: Combination ('robust', 3, 64, 0.2, 96, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 226: Combination ('robust', 3, 64, 0.2, 96, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 227: Combination ('robust', 3, 64, 0.2, 96, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 228: Combination ('robust', 3, 64, 0.2, 96, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 229: Combination ('robust', 3, 64, 0.2, 96, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 230: Combination ('robust', 3, 64, 0.2, 96, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 231: Combination ('robust', 3, 64, 0.2, 96, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 232: Combination ('robust', 3, 64, 0.2, 96, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 233: Combination ('robust', 3, 64, 0.2, 128, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 234: Combination ('robust', 3, 64, 0.2, 128, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 235: Combination ('robust', 3, 64, 0.2, 128, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 236: Combination ('robust', 3, 64, 0.2, 128, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 237: Combination ('robust', 3, 64, 0.2, 128, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 238: Combination ('robust', 3, 64, 0.2, 128, 0.001, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 239: Combination ('robust', 3, 64, 0.2, 128, 0.001, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 240: Combination ('robust', 3, 64, 0.2, 128, 0.001, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 241: Combination ('robust', 3, 96, 0.0, 64, 0.01, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 242: Combination ('robust', 3, 96, 0.0, 64, 0.01, 0.0, 0.001) already tested. Skipping.\n",
      "Iteration 243: Combination ('robust', 3, 96, 0.0, 64, 0.01, 0.001, 0.0) already tested. Skipping.\n",
      "Iteration 244: Combination ('robust', 3, 96, 0.0, 64, 0.01, 0.001, 0.001) already tested. Skipping.\n",
      "Iteration 245: Combination ('robust', 3, 96, 0.0, 64, 0.001, 0.0, 0.0) already tested. Skipping.\n",
      "Iteration 246: Training with params: {'iteration': 246, 'scaler': 'robust', 'model_depth': 3, 'layer_size': 96, 'dropout_rate': 0.0, 'batch_size': 64, 'learning_rate': 0.001, 'l1_rate': 0.0, 'l2_rate': 0.001}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 112\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Create and train the model\u001b[39;00m\n\u001b[1;32m    104\u001b[0m model \u001b[38;5;241m=\u001b[39m create_nn_model(input_dim\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    105\u001b[0m                         model_depth\u001b[38;5;241m=\u001b[39mdepth,\n\u001b[1;32m    106\u001b[0m                         layer_size\u001b[38;5;241m=\u001b[39mlayer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         l1_rate\u001b[38;5;241m=\u001b[39ml1_rate,\n\u001b[1;32m    110\u001b[0m                         l2_rate\u001b[38;5;241m=\u001b[39ml2_rate)\n\u001b[0;32m--> 112\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    113\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[reduce_lr, early_stopping])\n\u001b[1;32m    115\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    116\u001b[0m epochs_trained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:392\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    383\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    384\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    391\u001b[0m     )\n\u001b[0;32m--> 392\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    393\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    394\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m    395\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[1;32m    396\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[1;32m    397\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[1;32m    398\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    399\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m )\n\u001b[1;32m    402\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    404\u001b[0m }\n\u001b[1;32m    405\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:481\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    480\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 481\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[1;32m    482\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-metal/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 4: Hyperparameter Grid Search with Caching, Detailed Logging, and Memory Clearance\n",
    "\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define parameter grid (including batch_size)\n",
    "param_grid = {\n",
    "    'model_depth': [2, 3],\n",
    "    'layer_size': [32, 64, 96],\n",
    "    'dropout_rate': [0.0, 0.2],\n",
    "    'batch_size': [64, 96, 128],\n",
    "    'learning_rate': [1e-2, 1e-3],\n",
    "    'l1_rate': [0.0, 1e-3],\n",
    "    'l2_rate': [0.0, 1e-3]\n",
    "}\n",
    "\n",
    "# Define the scalers to try\n",
    "scaler_options = {\n",
    "    'robust': RobustScaler(),\n",
    "    'standard': StandardScaler()\n",
    "}\n",
    "\n",
    "# Ensure SAVE_DIR exists\n",
    "SAVE_DIR = 'model'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "results_json_path = os.path.join(SAVE_DIR, \"hyperparameter_search_results.json\")\n",
    "\n",
    "# Load existing results if available; otherwise, initialize empty list.\n",
    "if os.path.exists(results_json_path):\n",
    "    with open(results_json_path, 'r') as f:\n",
    "        results_all = json.load(f)\n",
    "else:\n",
    "    results_all = []\n",
    "\n",
    "# Create a set of keys for already tested combinations.\n",
    "# The key is a tuple: (scaler, model_depth, layer_size, dropout_rate, batch_size, learning_rate, l1_rate, l2_rate)\n",
    "tested_keys = set()\n",
    "for res in results_all:\n",
    "    key = (res['scaler'], res['model_depth'], res['layer_size'], res['dropout_rate'],\n",
    "           res['batch_size'], res['learning_rate'], res['l1_rate'], res['l2_rate'])\n",
    "    tested_keys.add(key)\n",
    "\n",
    "# Callbacks for training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=0)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-5, verbose=0)\n",
    "\n",
    "# Calculate total iterations for the tqdm progress bar\n",
    "total_iterations = len(scaler_options) * (\n",
    "    len(param_grid['model_depth']) *\n",
    "    len(param_grid['layer_size']) *\n",
    "    len(param_grid['dropout_rate']) *\n",
    "    len(param_grid['batch_size']) *\n",
    "    len(param_grid['learning_rate']) *\n",
    "    len(param_grid['l1_rate']) *\n",
    "    len(param_grid['l2_rate'])\n",
    ")\n",
    "pbar = tqdm(total=total_iterations, desc=\"Hyperparameter search progress\", unit=\"iter\")\n",
    "\n",
    "iteration_count = 0\n",
    "\n",
    "# Iterate over scaler options and hyperparameter combinations\n",
    "for scaler_name, scaler_instance in scaler_options.items():\n",
    "    # Fit the scaler on the training data and transform train data\n",
    "    X_train_scaled = scaler_instance.fit_transform(X_train)\n",
    "    \n",
    "    # Loop over all hyperparameter combinations\n",
    "    for depth, layer_size, dropout_rate, batch_size, learning_rate, l1_rate, l2_rate in itertools.product(\n",
    "            param_grid['model_depth'],\n",
    "            param_grid['layer_size'],\n",
    "            param_grid['dropout_rate'],\n",
    "            param_grid['batch_size'],\n",
    "            param_grid['learning_rate'],\n",
    "            param_grid['l1_rate'],\n",
    "            param_grid['l2_rate']):\n",
    "        \n",
    "        iteration_count += 1\n",
    "        # Create a unique key for the current parameter combination\n",
    "        current_key = (scaler_name, depth, layer_size, dropout_rate, batch_size, learning_rate, l1_rate, l2_rate)\n",
    "        \n",
    "        # Check if this combination has already been tested\n",
    "        if current_key in tested_keys:\n",
    "            print(f\"Iteration {iteration_count}: Combination {current_key} already tested. Skipping.\")\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "        \n",
    "        # Define parameters dictionary for this iteration\n",
    "        params = {\n",
    "            'iteration': iteration_count,\n",
    "            'scaler': scaler_name,\n",
    "            'model_depth': depth,\n",
    "            'layer_size': layer_size,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'l1_rate': l1_rate,\n",
    "            'l2_rate': l2_rate\n",
    "        }\n",
    "        print(f\"Iteration {iteration_count}: Training with params: {params}\")\n",
    "        \n",
    "        # Create and train the model\n",
    "        model = create_nn_model(input_dim=X_train.shape[1],\n",
    "                                model_depth=depth,\n",
    "                                layer_size=layer_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate,\n",
    "                                l1_rate=l1_rate,\n",
    "                                l2_rate=l2_rate)\n",
    "        \n",
    "        history = model.fit(X_train_scaled, y_train, epochs=1000, batch_size=batch_size,\n",
    "                            verbose=0, validation_split=0.2, callbacks=[reduce_lr, early_stopping])\n",
    "        \n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "        epochs_trained = len(history.history['loss'])\n",
    "        params.update({'val_loss': best_val_loss, 'epochs_trained': epochs_trained})\n",
    "        \n",
    "        print(f\"Iteration {iteration_count}: Completed with best_val_loss: {best_val_loss:.5f} after {epochs_trained} epochs\\n\")\n",
    "        \n",
    "        # Append the new result and update the tested keys\n",
    "        results_all.append(params)\n",
    "        tested_keys.add(current_key)\n",
    "        \n",
    "        # Save the updated results to the JSON file after each new test\n",
    "        with open(results_json_path, 'w') as f:\n",
    "            json.dump(results_all, f, indent=4)\n",
    "        \n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Clear session and garbage collect to free memory before the next iteration\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Convert all results to a DataFrame and print top 5 combinations\n",
    "results_df = pd.DataFrame(results_all)\n",
    "print(\"\\nTop 5 hyperparameter combinations:\")\n",
    "print(results_df.sort_values('val_loss').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visualization of Hyperparameter Search Results\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "# Visualize validation loss vs. layer size, differentiated by scaler and model depth\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=results_df, x='layer_size', y='val_loss', hue='scaler', style='model_depth', s=100)\n",
    "plt.title(\"Validation Loss vs. Layer Size (by scaler and model depth)\")\n",
    "plt.xlabel(\"Layer Size\")\n",
    "plt.ylabel(\"Validation MSE\")\n",
    "plt.legend(title=\"Scaler / Model Depth\")\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to check relationships among hyperparameters and performance\n",
    "sns.pairplot(results_df, vars=['scaler', 'model_depth', 'layer_size', 'dropout_rate', 'learning_rate', 'l1_rate', 'l2_rate', 'val_loss'])\n",
    "plt.suptitle(\"Pairplot of Hyperparameters and Validation Loss\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Training and Evaluating the Best Model on the Test Set\n",
    "# Identify the best hyperparameter combination (lowest validation loss)\n",
    "best_params = results_df.sort_values('val_loss').iloc[0].to_dict()\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(best_params)\n",
    "\n",
    "# Retrieve the best scaler option and fit it on the entire training data\n",
    "if best_params['scaler'] == 'robust':\n",
    "    best_scaler = RobustScaler()\n",
    "elif best_params['scaler'] == 'standard':\n",
    "    best_scaler = StandardScaler()\n",
    "else:\n",
    "    raise ValueError(\"Scaler type not recognized.\")\n",
    "\n",
    "X_train_scaled_best = best_scaler.fit_transform(X_train)\n",
    "X_test_scaled_best = best_scaler.transform(X_test)\n",
    "\n",
    "# Recreate and train the best model using the best scaler\n",
    "best_model = create_nn_model(input_dim=X_train.shape[1],\n",
    "                             model_depth=int(best_params['model_depth']),\n",
    "                             layer_size=int(best_params['layer_size']),\n",
    "                             dropout_rate=best_params['dropout_rate'],\n",
    "                             learning_rate=best_params['learning_rate'],\n",
    "                             l1_rate=best_params['l1_rate'],\n",
    "                             l2_rate=best_params['l2_rate'])\n",
    "\n",
    "history_best = best_model.fit(X_train_scaled_best, y_train, epochs=1000, batch_size=64,\n",
    "                              verbose=0, validation_split=0.2, callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history_best.history['loss'], label='Train Loss')\n",
    "plt.plot(history_best.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training History of the Best Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss = best_model.evaluate(X_test_scaled_best, y_test, verbose=0)\n",
    "print(\"Test set Mean Squared Error:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save Best Parameters, Model, Scaler, and All Hyperparameter Search Results\n",
    "SAVE_DIR = 'model'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Save the best hyperparameters to a JSON file\n",
    "best_params_path = os.path.join(SAVE_DIR, \"best_hyperparameters.json\")\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "print(\"Best hyperparameters saved to:\", best_params_path)\n",
    "\n",
    "# Save the best model\n",
    "model_filename = '3DCP_wANN_best.h5'\n",
    "best_model.save(os.path.join(SAVE_DIR, model_filename))\n",
    "print(\"Best model saved to:\", os.path.join(SAVE_DIR, model_filename))\n",
    "\n",
    "# Save the scaler using joblib\n",
    "scaler_filename = f\"scaler_{best_params['scaler']}.pkl\"\n",
    "joblib.dump(best_scaler, os.path.join(SAVE_DIR, scaler_filename))\n",
    "print(\"Scaler saved to:\", os.path.join(SAVE_DIR, scaler_filename))\n",
    "\n",
    "# Save the entire hyperparameter search results as CSV\n",
    "results_csv_path = os.path.join(SAVE_DIR, \"hyperparameter_search_results.csv\")\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "print(\"Hyperparameter search results saved to CSV at:\", results_csv_path)\n",
    "\n",
    "# Save the entire hyperparameter search results as JSON for additional documentation\n",
    "results_json_path = os.path.join(SAVE_DIR, \"hyperparameter_search_results.json\")\n",
    "results_df.to_json(results_json_path, orient=\"records\", indent=4)\n",
    "print(\"Hyperparameter search results saved to JSON at:\", results_json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
